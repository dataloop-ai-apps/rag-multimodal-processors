# Cursor Rules — Dataloop `dataloop.json` Manifest

Use this rules doc inside Cursor to scaffold and review DPK manifests quickly and consistently. If other manifests exist in the repo already, read those `dataloop.json` files and generate the new one similarly.

---

## Golden Rules

- **One DPK ⇢ One Module** (current limitation). Don’t ship multiple modules in a single DPK.
- **Versioning**  
  - Update **`.bumpversion.cfg`** and **`.dataloop.cfg`** together.  
  - A repo may contain **multiple DPKs**, but they **share the same `version`**.
- **Runner Images & Dockerfile**  
  - Build a Dockerfile with the right requirements **using Dave**.  
  - Reference its image in **`components.computeConfigs[*].runtime.runnerImage`** and/or **`components.services[*].runtime.runnerImage`**.
- **Public Tasks Apps**  
  - `.dataloop.cfg → public_app: true` exposes the app in **Dataloop Tasks** to everyone on the platform.

---

## Quick Start: Minimal Manifest Skeleton

```json
{
  "name": "my-dpk-name",
  "displayName": "My DPK",
  "version": "0.0.1",
  "scope": "public",
  "description": "Short description",
  "attributes": {
    "Provider": "Dataloop",
    "Category": "Application",
    "Media Type": ["Image"]
  },
  "codebase": {
    "type": "git",
    "gitUrl": "https://github.com/dataloop-ai-apps/<repo-name>.git",
    "gitTag": "0.0.1"
  },
  "components": {
    "integrations": [],
    "computeConfigs": [],
    "modules": [],
    "models": [],
    "services": [],
    "pipelineNodes": [],
    "converters": [],
    "toolbars": [],
    "applications": []
  }
}
```

---

## Integrations

> If you need a **project-local integration** (just for this project), add the component directly in the manifest.

**Example: key/value API key**

```json
{
  "components": {
    "integrations": [
      {
        "env": "API_KEY",
        "key": "openai",
        "value": "integration-id",
        "type": "key_value",
        "description": "API key for OpenAI platform"
      }
    ]
  }
}
```

**Rules**
- `env`: the environment variable name exposed to your runtime.
- `key`: short identifier for the integration (e.g., `"openai"`).
- `value`: the **integration ID** configured in the platform.
- `type`: `"key_value"` for simple secrets; add more only if platform supports.

---

## About DPKs

- **`dpk` = Dataloop PacKage**  
- The manifest file is **`dataloop.json`**.
- Include these in the manifest:
  - **Model components** (if any)
  - **Compute configs** (GPU/CPU variants as needed)
  - **Modules** (the single module definition + functions)
  - **Models** (name, module binding, scope, status, configuration, I/O)
  - **Applications** (for the Applications tab)
  - **Pipeline nodes / Converters / Toolbars** (formerly “slots”; **namespace** convention: `serviceName.moduleName.functionName`)

**Repo Config Files**
- **`.bumpversion.cfg`** — manage the shared semantic version.
- **`.dataloop.cfg`** — add flags like `public_app` (see Notes).

**Module Constraint**
- ❗ You **cannot** have **multiple modules** per DPK (breaking change risk). Split into multiple DPKs if needed.

**Docker Image**
- Create a **Dockerfile** (with Dave), publish, and set `runnerImage` in the compute config or service (see below).

---

## DPK Types & Repo Placement

1. **Onboarding-only attributes** → **`onboarding`** repo  
2. **Pipeline templates / solutions with _no code_** (only `dataloop.json`) → **`pipeline-templates`** repo  
3. **Everything else** (codeful) → new repo or an existing relevant repo (e.g., **`torch-models`**)

Each DPK may include **attributes** like `Category`, `Data Type`, etc.  
For **Onboarding**, set `Category: onboarding` and use attributes:  
- `onboarding card`  
- `onboarding tab`

---

## Compute Configs vs. Services

- **Compute Configs (`components.computeConfigs`)**
  - Best for **pipelines** to avoid service costs **until** the pipeline runs/installs.
  - Pipeline installations can **instantiate services** from the referenced compute config.

- **Services (`components.services`)**
  - Create when a long-lived runtime is needed (e.g., **panels**, **triggers** for **feature extraction**).
  - **Feature extraction rule**: after installing an app/model, no other action can create a service.  
    → **Create the service at install time** with **replicas scaled to `0`**.
  
**Example: two compute configs (CPU/GPU)**

```json
{
  "components": {
    "computeConfigs": [
      {
        "name": "my-cpu",
        "runtime": {
          "podType": "regular-xs",
          "concurrency": 1,
          "runnerImage": "gcr.io/.../apps/my-image:0.1.0",
          "autoscaler": { "type": "rabbitmq", "minReplicas": 0, "maxReplicas": 1, "queueLength": 100 }
        }
      },
      {
        "name": "my-gpu",
        "runtime": {
          "podType": "gpu-t4",
          "concurrency": 1,
          "runnerImage": "gcr.io/.../apps/my-image:0.1.0",
          "autoscaler": { "type": "rabbitmq", "minReplicas": 0, "maxReplicas": 2, "queueLength": 100 }
        }
      }
    ]
  }
}
```

**Example: service created on install with replicas 0**

```json
{
  "components": {
    "services": [
      {
        "name": "feature-extractor",
        "moduleName": "fe_module",
        "runtime": {
          "podType": "regular-s",
          "runnerImage": "gcr.io/.../apps/feature-extractor:1.0.0",
          "numReplicas": 0,
          "concurrency": 10,
          "autoscaler": { "type": "rabbitmq", "minReplicas": 0, "maxReplicas": 2, "queueLength": 10 },
          "preemptible": false
        },
        "maxAttempts": 3
      }
    ]
  }
}
```

---

## Modules & Functions (Single-Module Constraint)

```json
{
  "components": {
    "modules": [
      {
        "name": "my_module",
        "entryPoint": "runner.py",
        "className": "MyRunner",
        "computeConfig": "my-cpu",
        "initInputs": [],
        "functions": [
          {
            "name": "predict_items",
            "input": [{ "type": "Item[]", "name": "items" }],
            "output": [
              { "type": "Item[]", "name": "items" },
              { "type": "Annotation[]", "name": "annotations" }
            ],
            "displayName": "Predict Items",
            "description": "Run inference"
          }
        ]
      }
    ]
  }
}
```

**Tips**
- Keep **function I/O** explicit (`Item`, `Dataset`, `Model`, arrays).
- Add **`computeConfig`** per function if it should override the module default (e.g., GPU for training).
- Use clear `displayName`, `description`, `displayIcon` for UI.

---

## Models (Optional)

```json
{
  "components": {
    "models": [
      {
        "name": "pretrained-foo",
        "moduleName": "my_module",
        "scope": "project",
        "status": "pre-trained",
        "configuration": {
          "conf_threshold": 0.8
        },
        "inputType": "image",
        "outputType": "segment",
        "description": "Short model blurb",
        "labels": ["background", "object"]
      }
    ]
  }
}
```

---

## Pipeline Nodes / Applications / Converters / Toolbars

- **Pipeline Nodes** describe UI nodes that invoke functions:
  
  ```json
  {
    "components": {
      "pipelineNodes": [
        {
          "name": "consensus_agreement",
          "displayName": "Consensus Agreement",
          "description": "Process consensus items",
          "invoke": { "type": "function", "namespace": "my_module.consensus_agreement" },
          "categories": ["data"],
          "configuration": { "fields": [] },
          "scope": "node"
        }
      ]
    }
  }
  ```

- **Toolbars** (previously “slots”)  
  - **Namespace format**: `serviceName.moduleName.functionName`.

- **Applications**: add entries for the **Applications tab** if needed.

- **Converters**: define dataset/annotation converters here.

---

## Review Checklist (Paste into PRs)

- [ ] Single **module** only in this DPK  
- [ ] **`.bumpversion.cfg`** & **`.dataloop.cfg`** updated and aligned  
- [ ] **Dockerfile** built with **Dave**; **`runnerImage`** set  
- [ ] **Compute configs**: CPU/GPU as needed  
- [ ] **Services** created only when required; feature-extraction services start with **`numReplicas: 0`**  
- [ ] **Integrations** defined for project-local secrets with correct `env`, `key`, `value`, `type`  
- [ ] **Models** (if any) linked to the correct module; I/O types correct  
- [ ] **Pipeline nodes / Toolbars / Converters / Applications** defined and namespaced properly  
- [ ] **Attributes** include Category, Media Type, etc. For onboarding: `Category: onboarding` + attributes `onboarding card`, `onboarding tab`  
- [ ] **Scope** values correct (`public`, `project`, etc.)  
- [ ] **Autoscaler** config sane (min=0 where idle is desired)

---

## Examples

- **Scoring & Metrics App** — pipeline nodes, module, and a service definition (see example you provided).
- **DeepLabv3 Models** — dual compute configs (CPU deploy, GPU train/eval), single module, multiple pre-trained models (see example you provided).

> Use the provided examples as reference patterns for structure, naming, and configuration fields.

---

## Snippets Library

**Add a GPU training override to a function**
```json
{
  "name": "train_model",
  "computeConfig": "my-gpu",
  "input": [{ "type": "Model", "name": "model" }],
  "output": [{ "type": "Model", "name": "model" }],
  "displayName": "Train a Model",
  "description": "Function to train the model"
}
```

**Toolbar namespace reminder**
```text
serviceName.moduleName.functionName
```

**Public app flag (`.dataloop.cfg`)**
```ini
[app]
public_app = true
```
